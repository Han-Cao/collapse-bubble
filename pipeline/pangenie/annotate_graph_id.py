#!/usr/bin/env python3

# Map variants in PanGenie graph VCF to collapsed variants
# Created: 02-Oct-2024
# Author: Han Cao

import argparse
from collections import defaultdict

import pysam
import pandas as pd


def parse_wave_vcf(vcf: pysam.VariantFile) -> pd.DataFrame:
    """ Read wave VCF, store ID mapping to dataframe """

    # wave vcf may not have all chr in the graph VCF, so we process by existing chr
    id_map_dict = defaultdict(list) # chr -> list of ID mapping
    for variant in vcf.fetch():
        id_map_dict[variant.chrom].append({'Variant_ID': variant.id, 'Pangenie_ID': variant.info['ID'][0]})
    
    df = pd.DataFrame()
    for k, v in id_map_dict.items():
        df_new = pd.DataFrame(v)
        df_new['CHROM'] = k
        df = pd.concat([df, df_new], ignore_index=True)

    return pd.DataFrame(df)


def contig_workder(graph_vcf: pysam.VariantFile, outvcf: pysam.VariantFile, 
                   df_id_map: pd.DataFrame, contig: str) -> None:
    """ Main worker per contig """

    df_work = df_id_map[df_id_map['CHROM'] == contig]
    # generate a dict for mapping
    # Pangenie_ID -> colon separated collapse IDs
    id_map = df_work.groupby('Pangenie_ID')['Collapse_ID'].apply(lambda x: ':'.join(x)).to_dict()

    # annotate ID and write to output
    for variant in graph_vcf.fetch(contig):
        var_out = variant.copy()
        
        new_id = []
        # INFO/ID:
        # one string for one alt 
        # ":" separated for multiple variants from the same allele
        for allele_ids in variant.info['ID']:
            id_lst = [] # collapse ID str per allele
            for pangenie_id in allele_ids.split(':'):
                id_lst.append(id_map[pangenie_id])
            new_id.append(':'.join(id_lst))
        
        var_out.info['ID'] = tuple(new_id)

        outvcf.write(var_out)


def main(args: argparse.Namespace):
    # read input data
    graph_vcf = pysam.VariantFile(args.graph_vcf, 'rb')
    wave_vcf = pysam.VariantFile(args.wave_vcf, 'rb')
    outvcf = pysam.VariantFile(args.outvcf, 'w', header=graph_vcf.header)
    df_collapse = pd.read_csv(args.mapping, sep='\t')
    df_collapse = df_collapse[['Variant_ID', 'Collapse_ID']] # only keep columns we need

    # map variant ID
    df_id_map = parse_wave_vcf(wave_vcf)
    df_id_map = pd.merge(df_id_map, df_collapse, on='Variant_ID', how='left')
    df_id_map['Collapse_ID'] = df_id_map['Collapse_ID'].fillna(df_id_map['Variant_ID'])

    # process each contig
    contigs = sorted(df_id_map['CHROM'].unique())
    for contig in contigs:
        contig_workder(graph_vcf, outvcf, df_id_map, contig)

    outvcf.close()
    wave_vcf.close()
    graph_vcf.close()
    

if __name__ == '__main__':
    parser = argparse.ArgumentParser(prog='graph_to_collapse.py', description='Map variants in PanGenie graph VCF to collapsed variants')
    parser.add_argument('--graph-vcf', required=True, metavar='VCF', type=str, help='Graph VCF file generated by PanGenie pipeline')
    parser.add_argument('--wave-vcf', required=True, metavar='VCF', type=str, help='Decomposed VCF file generated by vcfwave')
    parser.add_argument('--mapping', required=True, metavar='TXT', type=str, help='Table mapping original SV IDs to collapsed SV IDs')
    parser.add_argument('-o', '--outvcf', required=True, metavar='VCF', type=str, help='Output VCF file')
    
    args = parser.parse_args()
    main(args)
