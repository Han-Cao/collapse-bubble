#!/usr/bin/env python3

# Map variants in PanGenie graph VCF to collapsed variants
# Last update: 11-Jul-2025
# Author: Han Cao

import argparse
from collections import defaultdict

import pysam
import pandas as pd


def parse_wave_vcf(vcf: pysam.VariantFile) -> pd.DataFrame:
    """ Read wave VCF, store ID mapping to dataframe """

    # wave vcf may not have all chr in the graph VCF, so we process by existing chr
    id_map_dict = defaultdict(list) # chr -> list of ID mapping
    for variant in vcf.fetch():
        id_map_dict[variant.chrom].append({'Variant_ID': variant.id, 'Pangenie_ID': variant.info['ID'][0]})
    
    df = pd.DataFrame()
    for k, v in id_map_dict.items():
        df_new = pd.DataFrame(v)
        df_new['CHROM'] = k
        df = pd.concat([df, df_new], ignore_index=True)

    return pd.DataFrame(df)


def parse_merge_dup_vcf(vcf: pysam.VariantFile) -> pd.DataFrame:
    """ Read merge_duplicates output, store duplicated variants """

    dup_lst = []
    for variant in vcf.fetch():
        # no duplicates
        if 'DUP' not in variant.info:
            continue
        # Header: <ID=DUP,Number=.>
        for dup_id in variant.info['DUP']:
            dup_lst.append({'Variant_ID': variant.id, 'Duplicate_ID': dup_id})
    
    df_dup = pd.DataFrame(dup_lst)

    return df_dup


def contig_workder(graph_vcf: pysam.VariantFile, outvcf: pysam.VariantFile, 
                   df_id_map: pd.DataFrame, contig: str) -> None:
    """ Main worker per contig """

    df_work = df_id_map[df_id_map['CHROM'] == contig]
    # generate a dict for mapping
    # Pangenie_ID -> colon separated collapse IDs
    id_map = df_work.groupby('Pangenie_ID')['Collapse_ID'].apply(lambda x: ':'.join(x)).to_dict()

    # annotate ID and write to output
    for variant in graph_vcf.fetch(contig):
        var_out = variant.copy()
        
        new_id = []
        # INFO/ID:
        # one string for one alt 
        # ":" separated for multiple variants from the same allele
        for allele_ids in variant.info['ID']:
            id_lst = [] # collapse ID str per allele
            for pangenie_id in allele_ids.split(':'):
                id_lst.append(id_map[pangenie_id])
            new_id.append(':'.join(id_lst))
        
        var_out.info['ID'] = tuple(new_id)

        outvcf.write(var_out)


def main(args: argparse.Namespace):
    # read input data
    graph_vcf = pysam.VariantFile(args.graph_vcf, 'rb')
    wave_vcf = pysam.VariantFile(args.wave_vcf, 'rb')
    mergedup_vcf = pysam.VariantFile(args.mergedup_vcf, 'rb')
    outvcf = pysam.VariantFile(args.outvcf, 'w', header=graph_vcf.header)
    df_collapse = pd.read_csv(args.mapping, sep='\t')
    df_collapse = df_collapse[['Variant_ID', 'Collapse_ID']] # Variant_ID collapse to Collapse_ID
    df_dup = parse_merge_dup_vcf(mergedup_vcf) # Duplicate_ID collapse to Variant_ID
    df_id_map = parse_wave_vcf(wave_vcf) # Variant_ID -> Pangenie_ID

    # append duplicates to df_collapse
    df_dup = pd.merge(df_dup, df_collapse, on='Variant_ID', how='left')
    # if Variant_ID is collapsed, equivalent to collapse Duplicate_ID to Collapse_ID
    df_dup_with_collapse = df_dup[df_dup['Collapse_ID'].notna()][['Duplicate_ID', 'Collapse_ID']]
    df_dup_with_collapse = df_dup_with_collapse.rename(columns={'Duplicate_ID': 'Variant_ID', 'Collapse_ID': 'Collapse_ID'})
    # if Variant_ID is not collapsed, equivalent to collapse Duplicate_ID to Variant_ID
    df_dup_no_collapse = df_dup[df_dup['Collapse_ID'].isna()][['Duplicate_ID', 'Variant_ID']]
    df_dup_no_collapse = df_dup_no_collapse.rename(columns={'Duplicate_ID': 'Variant_ID', 'Variant_ID': 'Collapse_ID'})
    df_collapse = pd.concat([df_collapse, df_dup_with_collapse, df_dup_no_collapse], ignore_index=True)

    # map variant ID
    df_id_map = pd.merge(df_id_map, df_collapse, on='Variant_ID', how='left')
    df_id_map['Collapse_ID'] = df_id_map['Collapse_ID'].fillna(df_id_map['Variant_ID']) # map to itself

    # process each contig
    contigs = sorted(df_id_map['CHROM'].unique())
    for contig in contigs:
        contig_workder(graph_vcf, outvcf, df_id_map, contig)

    outvcf.close()
    wave_vcf.close()
    graph_vcf.close()
    

if __name__ == '__main__':
    parser = argparse.ArgumentParser(prog='graph_to_collapse.py', description='Map variants in PanGenie graph VCF to collapsed variants')
    parser.add_argument('--graph-vcf', required=True, metavar='VCF', type=str, help='Graph VCF file generated by PanGenie pipeline')
    parser.add_argument('--wave-vcf', required=True, metavar='VCF', type=str, help='vcfwave output VCF')
    parser.add_argument('--mergedup-vcf', required=True, metavar='VCF', type=str, help='merge_duplicates.py output VCF')
    parser.add_argument('--mapping', required=True, metavar='TXT', type=str, help='Table mapping original SV IDs to collapsed SV IDs')
    parser.add_argument('-o', '--outvcf', required=True, metavar='VCF', type=str, help='Output VCF file')
    
    args = parser.parse_args()
    main(args)